{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aee55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fab8c3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the tokenizer from the saved file\n",
    "with open('tokenizer.pkl', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "print(\"Tokenizer loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb160236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "multimodal_model = load_model('multimodel_model.h5')\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a605889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\@\\w+|\\#', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "65833895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proprocess_image(image_path,  target_size=(224, 224)):\n",
    "    try:\n",
    "        response = requests.get(image_path)\n",
    "        if response.status_code != 200:\n",
    "            return np.zeros((target_size[0], target_size[1], 3))\n",
    "        image_data = BytesIO(response.content)\n",
    "        \n",
    "        image = Image.open(image_data)\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        image = image.resize(target_size)\n",
    "        image = img_to_array(image) / 255.0\n",
    "    \n",
    "        return image\n",
    "    except Exception as e:\n",
    "        return np.zeros((target_size[0], target_size[1], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "98191f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_post_1 = {\n",
    "    \"_id\": \"12345\",\n",
    "    \"image_url\": \"https://res.cloudinary.com/dswg5in7u/image/upload/v1749163669/1034948245380915200_wr612j.jpg\",\n",
    "    \"content\": \"why don't we beat that nigga ass\"\n",
    "}\n",
    "\n",
    "dummy_post_2 = {\n",
    "    \"_id\": \"123456\",\n",
    "    \"image_url\":\"https://res.cloudinary.com/dswg5in7u/image/upload/v1749164207/1035252480215592966_kavagy.jpg\",\n",
    "    \"content\": \"EVERYbody calling you Nigger now! https://t.co/6mguJ6KIB\"\n",
    "}\n",
    "\n",
    "dummy_post_3 = {\n",
    "    \"_id\": \"123456\",\n",
    "    \"image_url\":\"https://res.cloudinary.com/dswg5in7u/image/upload/v1746368159/DreamerDB/bplmtumngvu9bjr0bhgu.png\",\n",
    "    \"content\": \"Beautiful girl\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "83a69c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step\n"
     ]
    }
   ],
   "source": [
    "# Get the image path from the dataset\n",
    "# Resize image to fit model input size\n",
    "img_array = proprocess_image(dummy_post_3[\"image_url\"])\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension (1, 224, 224, 3)\n",
    "img_array = preprocess_input(img_array)  # Preprocessing for ResNet50\n",
    "\n",
    "# Preprocess the text using the tokenizer (convert text to sequence)\n",
    "cleaned_text =  preprocess_text(dummy_post_3[\"content\"])\n",
    "\n",
    "text_sequence = tokenizer.texts_to_sequences([cleaned_text])\n",
    "text_padded = pad_sequences(text_sequence, maxlen=100)  # Adjust `maxlen` based on your model's input length\n",
    "\n",
    "# Get multimodal model prediction (for multimodal classification)\n",
    "multimodal_prediction = multimodal_model.predict([img_array, text_padded])\n",
    "\n",
    "multimodal_predicted_label = np.argmax(multimodal_prediction, axis=1)  # Multi-class classification\n",
    "predicted_label = multimodal_predicted_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f8ff0632",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_prediction =  [round(prob * 100, 2) for prob in multimodal_prediction[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b1d6a18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float32(3.75),\n",
       " np.float32(0.55),\n",
       " np.float32(6.01),\n",
       " np.float32(0.94),\n",
       " np.float32(7.06),\n",
       " np.float32(81.69)]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b4948614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multimodal Model Prediction: OtherHate\n"
     ]
    }
   ],
   "source": [
    "# Label mappings for multimodal model\n",
    "multimodal_label_mapping = {\n",
    "    0: \"NotHate\",\n",
    "    1: \"Racist\",\n",
    "    2: \"Sexist\",\n",
    "    3: \"Homophobe\",\n",
    "    4: \"Religion\",\n",
    "    5: \"OtherHate\"\n",
    "}\n",
    "\n",
    "# Print the predicted label\n",
    "print(f\"Multimodal Model Prediction: {multimodal_label_mapping[predicted_label]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
